[
  {
    "objectID": "posts/2022-03-23-evrimsel-genombilim/index.html",
    "href": "posts/2022-03-23-evrimsel-genombilim/index.html",
    "title": "Evrimsel Genombilim Yaz Okulu 2022",
    "section": "",
    "text": "Geleneksel hale gelmiş etkinlikler, akademik kültürün verimli bir şekilde aktarılması açısından oldukça önemli bir yer tutuyor. Bu sayede, belli bir alanda çalışan araştırmacılar ara sıra bir araya gelerek yeni yöntemleri, en güncel bilgileri, ve güncel çalışmalarını paylaşıyorlar. Ne güzel ki ülkemizde de artık geleneksel hale gelmiş bir çok etkinlik var ve bu etkinliklerden bir tanesi de Tuğçe Bilgin Sonay ve Sibel Küçükyıldırım Çelik tarafından organize edilen evrimsel genombilim uygulamalı eğitim serisi.\nTuğçe ve Sibel her yıl Türkiye’nin farklı şehirlerinde bu etkinlikleri organize ediyor ve lisansüstü seviyede araştırma yapan genç bilim insanlarını, biyoinformatik disiplininin evrimsel biyoloji alanında en güncel uygulamaları hakkında bilgilendirmeye çalışyor.\nDaha önce 2020 yılı başında, Ege Üniversitesinde Evren Koban Baştanlar ev sahipliğinde yapılan etkinliğe katılma fırsatı bulmuş ve metagenomik alanındaki bilgilerimi aktarmıştım.\nDaha sonra bu etkinliği Mersin Üniversitesinde düzenleme fikri ortaya çıktı ancak pandemi buna engel oldu ve geçen yıl çevrimiçi bir etkinlik düzenlemek durumunda kaldık…\nSonunda bu hayali gerçekleştiriyoruz! :)\nHepinizi 20 - 24 Haziran 2022’de Mersin Üniversitesi, Biyoteknoloji bölümünde düzenlenecek olan Evrimsel Genombilim yaz okulu etkinliğimize bekliyoruz. Etkinliğimizin internet sitesini ziyaret ederseniz daha ayrıntılı bilgiler alabilirsiniz:\nhttps://egenombilim.wixsite.com/home\n\n\n\nEvrimsel Genombilim uygulamalı eğitimi poster"
  },
  {
    "objectID": "posts/2023-02-12-quake/index.html",
    "href": "posts/2023-02-12-quake/index.html",
    "title": "Kahramanmaraş Depremi",
    "section": "",
    "text": "Geçtiğimiz haftanın nasıl geçtiğini anlayamadım. Son bir aydır, Avrupa Birliği tarafından desteklenen NEOMATRIX projesi kapsamında bir çalıştay hazırlığı içerisindeydik. Bu kapsamda, Stokholm, Paris ve Ankara’dan hocalar gelecek ve üzerinde çalıştığımız bir antik metagenomik analiz protokolü hakkında bir çalıştay gerçekleştirecektik.\nPazar akşamı ekip gelmiş, hazırlıklar olabildiğinde tamamlanmış ve artık çalıştay aşamasına geçmeye yaklaşmıştık. Ancak, Pazartesi sabaha karşı depremle uyandık…\nOlayın bu kısmına çok fazla giremeyeceğim ancak sonuç olarak çalıştay ve bütün toplantılar iptal oldu. Yurtdışından gelen hocaları ise Ankara üzerinden ülkelerine ulaşmalarını sağladık. Hepimize geçmiş olsun.\nBen de bir yandan telefon trafiği içerisindeyken, aklımın bir köşesinde “Acaba ülkemizde gerçekleşen depremleri inceleyebilir miyiz?” sorusu dönüyordu.\nTabii ki bir deprem bilimci ya da jeolog değilim. Bu konuda asla ahkam kesemem, ancak hali hazırda açık bir şekilde paylaşılan veriyi kullanarak bazı denemeler yapabiliriz. Bu yazıda amacım sadece ülkemizin bir deprem kuşağında olduğunu göstermek, ve depremlerin, fay hatları üzerinde nasıl hareket ettiğini görselleştirmek.\n\n\n\n\nGenel görünüm\nÖncelikle 1990 yılından bu yana yaşanmış depremlerin verisini AFAD internet sitesinden indirdim. Görünüşe göre veri Türkiye’de bulunan istasyonlar tarafından hissedilmiş bütün deprem kayıtlarını içeriyor. Dolayısıyla veriyi bir miktar işlemeniz gerekebilir. Ancak öncelikle verinin şeklini inceleyelim.\nVerimiz 402212 gözlem ve 10 değişkenden oluşuyor. Yani her satır bir deprem hareketini gösterirken, her sütün ise bu depremde gözlenen değişkenleri ifade ediyor.\nSütun isimlerine bakarsak:\n\n\n [1] \"Date\"      \"Longitude\" \"Latitude\"  \"Depth\"     \"Rms\"       \"Type\"     \n [7] \"Magnitude\" \"Location\"  \"EventID\"   \"index\"    \n\n\n\nDate: Olayın tarihi\nLongitude: Boylam\nLatitude: Enlem\nDepth: Derinlik\nRms: Algılanma süresi (saniye)\nType: Ölçüm tipi\nMagnitude: Şiddet\nLocation: Deprem bölgesi\nEventID: Depremin kodu\n\nBu bilgilere göre, ülkemiz istasyonları tarafından algılanan 402212 tane deprem olmuş. Bu depremlerin şiddetlerini bir histogram olarak incelersek daha açıklayıcı olacaktır (Figür 1).\n\n\n\n\n\nFigür 1: Veri setinde bulunan deprem şiddetlerinin histogram görüntüsü\n\n\n\n\nGördüğünüz gibi bu depremlerin büyük bir kısmı aslında düşük şiddete sahip. Sadece 37 tanesi 6’nın üzerinde gerçekleşmiş. Tabii bu veriye, ülkemize yakın noktalarda gerçekleşmiş depremler de dahi: Doğanın politik sınırları yok.\nAncak bu veri büyük oranda gürültü içeriyor. Örnek vermek gerekirse 4’den düşük şiddete sahip depremler bizim için anlamlı olmayabilir. Bu yüzden öncelikle 4’den düşük depremleri filtreleyelim.\n\n\n\n\n\n\nPeki bu depremler nerelerde odaklanmış? Enlem ve boylam bilgisinin histogramını oluşturursak bunu rahatlıkla gösterebiliriz. Figür 2’da gösterilen histogramlardaki tepe noktaları, aslında hangi enlem ve boylamlarda en fazla depremin oluştuğunu göstermektedir. Neredeyse bütün enlemlerde deprem gözlenirken, aslında asıl farklılık boylamlarda. Depremler Ege, ve Doğu Anadolu kısımlarında yoğunlaşmış.\nTabii ki burada 1990 öncesi depremler yok. Onlar da olsaydı daha farklı bir şeklimiz olurdu.\n\n\n\n\n\n\n\n(a) Enlem\n\n\n\n\n\n\n\n(b) Boylam\n\n\n\n\nFigür 2: Depremlerin enlem ve boylamlara göre dağılımı\n\n\nPeki depremlerin oluştuğu derinlik ve depremin şiddeti arasında bir bağlantı var mı? Bunu da bir nokta grafiği kullanarak gösterebiliriz (Figür 3). Bu şekle baktığımızda aslında depremlerin çoğunlukla yüzeye yakın bölgelerde oluştuğunu görebiliriz. Ayrıca, yüzeye yakın olan depremlerin de şiddetli olma ihtimali bir hayli fazla.\n\n\n\n\n\nFigür 3: Depremin oluştuğu derinlik ve şiddet arasındaki ilişki\n\n\n\n\nBu noktadan sonra veriyi sadeleştirmek için, 4’den küçük olan depremleri filtreledim. Filtrelenmiş veriyi artık Türkiye haritasına oturtabiliriz (Figür 4). Bu şekle baktığımızda aslında görmemiz gereken şey noktaların nerelerde yoğunlaştığı. Noktaların daha yoğun olduğu bölgeler, bize depremlerin de yoğun olarak oluştuğu yerleri göstermektedir.\nDikkat edersek, Kuzey Anadolu ve Doğu Anadolu fay hatları üzerinde yoğun bir deprem hareketliliği görülebilir.\n\n\n\n\n\nFigür 4: Ülkemizden algılanan 4 şiddetinden büyük depremlerin gösterimi\n\n\n\n\nŞimd haritayı biraz daha Türkiye üzerine odaklayalım ve depremlerin büyüklüklerini de görselleştirmeye ekleyelim. Bu sayede büyük depremlerin nerelerde olduğunu görebiliriz (Figür 5). Bu şekilde, kırmızı noktaların yoğunluğu arttıkça, o bölgede güçlü bir deprem olduğu anlaşılmaktadır.\n\n\n\n\n\nFigür 5: Ülkemizde yaşanan 4 şiddetindeki büyük depremlerin\n\n\n\n\nBu şekil bence Türkiye’nin gerçekten bir deprem bölgesi olduğu gerçeğini çok güzel bir şekide anlatıyor. Depremler Batı ve Doğu bölgelerimizde yoğunlaşmış durumda. Orta Anadolu’dan başlayarak, Akdeniz’in ortasına kadar inen bölgede ise fazla deprem görünmüyor.\n\n\nKahramanmaraş depremi ve Doğu Anadolu fay hattı\nAncak benim ilgilendiğim nokta şu an için Kahramanmaraş depremi. Şimdi biraz daha bu bölgeye odaklalanalım. Acaba fay hattı hangi yönlere doğru kırılmış olabilir? Küçük bir animasyonla bunu görselleştirebilriz (Figür 6). Harika! Önce ilk depremle kuzey-güney ekseninde kırılan fay hattı, daha sonra ikinci depremle doğu-batı ekseninde kırılmaya başlıyor.\n\n\n\n\n\nFigür 6: Kahramanmaraş bölgesinde yaşanan depremin animasyonu\n\n\n\n\n\n\nDoğu Anadolu fayının kırılması\nFay hatlarının doğudan batıya doğru kırıldığını haberlerden duymuşsunuzdur mutlaka. Küçük bir aramayla, Doğu Anadolu fayı üzerinde bulunan deprem serilerine ulaştım:\n\nAdana Ceyhan depremi (1998)\nBingöl depremi (2003)\nElazığ depremleri (2003, 2010)\nGaziantep Kahramanmaraş depremi (2023)\n\nAcaba bu bilgiyi, elimizdeki veriyi kullanarak görselleştirebilir miyiz? Bunun için elimizdeki veriyi 1998 Adana Ceyhan depreminden sonraki depremleri içerecek şekilde filtreliyorum. Ayrıca depremleri sadece Doğu Anadolu fay hattını içerecek şekilde filtreliyorum ki deprem serisini daha rahat anlayalım (Figür 7).\n\n\n\n\n\nFigür 7: Doğu Anadolu fay hattının kırılması\n\n\n\n\nŞekle baktığımızda gerçekten Doğu Anadolu fayı ekseninde bir hareketlilik göze çarpıyor. 1998 yılındaki Adana depreminin ardından oluşan büyük depremler, doğu-batı ekseninde gerçekleşiyor.\n\n\nSonuç\nBu yazıyı yazma amacım aslında derin bir deprem incelemesi yapmak değildi - ki zaten uzmanlık alanım değil. Kamuya açık verileri kullanarak neler yapabiliriz onu görmek istedim. Buradaki görselleştirmelere daha da geliştirilebilir. O da sonraki yazıların konusu olsun.\n\n\nTeşekkür\nAnimasyonlar için gerekli kodu oluşturan Arda Sevkar’a teşekkürler."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "In this page you could find my blog posts.\nNot too many content for now but I will write in Turkish and English.\nI will use Turkish when I try to explain some concepts to studends or general audience in Turkey.\nI will use English to write about academic concepts and in-depth data analysis posts.\n\nPosts\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nKahramanmaraş Depremi\n\n\n\n\n\n\n\ntürkçe\n\n\nveri-analizi\n\n\ndeprem\n\n\nR\n\n\nmersin\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\nEmrah Kırdök, Ph.D.\n\n\n\n\n\n\n  \n\n\n\n\nEvrimsel Genombilim Yaz Okulu 2022\n\n\n\n\n\n\n\ntürkçe\n\n\nbioinformatics\n\n\nekoevo\n\n\nmersin\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2022\n\n\nEmrah Kırdök, Ph. D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Lectures",
    "section": "",
    "text": "At Mersin University Department of Biotechnology, I am giving ten courses that span to various themes. These lectures are in Turkish now and they are maintained as Github repositories. So feel free to fork and contribute!\n\nData Analysis in Life Sciences (TR) site\n\nUndergrad level Data Analysis course\nUndergrad level Statistical Learning course\nGrad level Data Analysis in Biotechnology course\n\nBioinformatics (TR) site\n\nUndergrad level Bioinformatics\nGrad level Advanced Bioinformatics"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi!\nThis is Emrah. I am an Assistant Prof. at Mersin University Department of Biotechnology. In this website I will be blogging about academia, data science, and ancient DNA.\n\nWork Experience\n2019 - Current: Mersin University, Department of Biotechnology\n2018 - 2019: Stockholm University, Department of Archaelogy and Classical Studies\n2010 - 2016: Gebze Technical University, Department of Molecular Biology and Genetics"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "At Aykut Kence Evolution Meeting 2022, I presented a talk named What does Ancient human microbes tell us? The talk is in Turkish.\n\nvideo"
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#who-am-i",
    "href": "presentations/2023-04-19-cpg/index.html#who-am-i",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Who am I?",
    "text": "Who am I?\n\nEmrah Kırdök, Ph.D.\nTrained as a biologist\nWorking on ancient metagenomics\nGiving lectures on bioinformatics and data analysis\n\n\nHi I am Emrah Kırdök. I think most of you already know me. I am working at Mersin University, deparment of biotechnology. Currently, I am working on ancient metagenomics and bioinformatics. Also I am teaching bioinformatics and data analysis at graduate and undergraduate level.\nNora and Zoe asked me to present some of my experiences and struggles in ancient metagenomics studies and how aMeta helped me to deal these.\nAfter some thought, I’ve come up with this presentation."
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#outline",
    "href": "presentations/2023-04-19-cpg/index.html#outline",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Outline",
    "text": "Outline\n\nAncient metagenomics is still a new discipline\nWe do not have very well defined methods\nSome struggle is inevitable\nLessons learnt, some good practice and tricks\nHow aMeta helped me to understand snakemake\n\n\nTrained as a biologist, I moved to bioinformatics and ancient metagenomics field after my Ph.D. studies. However, this change was not really easy.\nBioinformatics is mostly done by trial and error. So, you run something, you observe, you fix and run again. And even ancient metagenomics is particularly hard, since it is still a young filed. There are just a handful of methods out there, and in most occasions you’ll have to get your hands dirty.\nBut there are some tricks and tips that make your life easier in the long run. In this presentation I will explain you my experience on ancient metagenomics from the start and show you some tricks."
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#bioinformatics-methdodology",
    "href": "presentations/2023-04-19-cpg/index.html#bioinformatics-methdodology",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Bioinformatics methdodology",
    "text": "Bioinformatics methdodology\nA simple methodology\n\n\n\n\n\n\n\ng\n\n  \n\ninput1\n\n Input1   \n\ntool\n\n Tool   \n\ninput1->tool\n\n    \n\ninput2\n\n Input2   \n\ninput2->tool\n\n    \n\nparameters\n\n parameters   \n\nparameters->tool\n\n    \n\noutput1\n\n Output1   \n\ntool->output1\n\n    \n\noutput2\n\n Output2   \n\ntool->output2\n\n   \n\n\n\n\n\n\nHowever, generally it is more complicated. You will have more than one input and more then one outputs. Often, you will have some parameters to fine tune."
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#bioinformatics-methdodology-1",
    "href": "presentations/2023-04-19-cpg/index.html#bioinformatics-methdodology-1",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Bioinformatics methdodology",
    "text": "Bioinformatics methdodology\nActually it is much more complicated…\n\n\n\n\n\n\n\ng\n\n  \n\ninput1\n\n Input1   \n\ntool1\n\n Tool1   \n\ninput1->tool1\n\n    \n\ninput2\n\n Input2   \n\ninput2->tool1\n\n    \n\nparameters\n\n parameters   \n\nparameters->tool1\n\n    \n\noutput1\n\n Output1   \n\ntool1->output1\n\n    \n\noutput2\n\n Output2   \n\ntool1->output2\n\n    \n\ntool2\n\n Tool2   \n\noutput2->tool2\n\n    \n\noutput3\n\n Output3   \n\ntool2->output3\n\n    \n\nmoreparameters\n\n moreparameters   \n\nmoreparameters->tool2\n\n   \n\n\n\n\n\n\nThe core idea of bioinformatics methodology is to combine several tools into one neat workflow.\nBut it is much more complicated then that. To do a bionformatics research, you’ll need to use a lot of different tools, a lot of files, different paramters.\nOften you’ll need to optimize parameters to get the correct result.\nThis is the general idea of bioinformatics work style."
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#ancient-metagenomics-methodology",
    "href": "presentations/2023-04-19-cpg/index.html#ancient-metagenomics-methodology",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Ancient metagenomics methodology",
    "text": "Ancient metagenomics methodology\nAnd in ancient metagenomics, it is much more complicated…\n\n\n\n\n\n\n\ng\n\n  \n\nfastq\n\n Fastq file   \n\nclassification\n\n Classification   \n\nfastq->classification\n\n    \n\noutput\n\n Classification Output   \n\nauthentication\n\n Extract aDNA reads and authenticate   \n\noutput->authentication\n\n    \n\nclassification->output\n\n    \n\nauthentication_1\n\n authentication_1   \n\nauthentication->authentication_1\n\n    \n\nauthentication_2\n\n authentication_2   \n\nauthentication->authentication_2\n\n    \n\nauthentication_3\n\n authentication_3   \n\nauthentication->authentication_3\n\n    \n\nauthentication_4\n\n authentication_4   \n\nauthentication->authentication_4\n\n    \n\nauthentication_N\n\n authentication_N   \n\nauthentication->authentication_N\n\n    \n\ndatabase\n\n database   \n\ndatabase->classification\n\n    \n\ndatabase->authentication\n\n    \n\nFinal Report\n\n Final Report   \n\nauthentication_1->Final Report\n\n    \n\nauthentication_2->Final Report\n\n    \n\nauthentication_3->Final Report\n\n    \n\nauthentication_4->Final Report\n\n    \n\nauthentication_N->Final Report\n\n   \n\n\n\n\n\n\nAnd in ancient metagenomics, this is much more harder. Generally, we classify DNA reads in fastq files using a reference sequence collection. THis collection contains DNA sequences that have known taxonomical ranks. By comparing each sequence to this collection, we try to identify the taxonomic origin of each DNA read.\nHowever, in ancient metaggneomics, we also need to extract DNA sequences and authenticate the ancient status. So, at the end we do not know how many bacteria we have."
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#ancient-metagenomics-methodology-1",
    "href": "presentations/2023-04-19-cpg/index.html#ancient-metagenomics-methodology-1",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Ancient metagenomics methodology",
    "text": "Ancient metagenomics methodology\nIt is even more complicated in a real situation:\n\nThe aMeta Workflow"
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#authentication-part-of-the-pipeline",
    "href": "presentations/2023-04-19-cpg/index.html#authentication-part-of-the-pipeline",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Authentication part of the pipeline",
    "text": "Authentication part of the pipeline\n\nIt would be very hard to authenticate one by one"
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#workflows-1",
    "href": "presentations/2023-04-19-cpg/index.html#workflows-1",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Workflows",
    "text": "Workflows\n\nBash scripts are quite easy to write\nBut, every time you run it starts from beginning\nEvery bash script could be specific to one job\nJob dependency (with slurm?)"
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#my-first-workflow",
    "href": "presentations/2023-04-19-cpg/index.html#my-first-workflow",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "My first workflow",
    "text": "My first workflow\n\n\nMy first workflow.\n\nvery fast\ncompletely on bash\ncan preserve job dependencies\nbut it runs from the beginning"
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#snakemake",
    "href": "presentations/2023-04-19-cpg/index.html#snakemake",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Snakemake",
    "text": "Snakemake\n\naMeta allowed me to learn snakemake\nSnakemake changed my view\nA fully robust system that can automatically send slurm jobs"
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#snakemake-1",
    "href": "presentations/2023-04-19-cpg/index.html#snakemake-1",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Snakemake",
    "text": "Snakemake"
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#helps-you-to-keep-a-tidy-folder",
    "href": "presentations/2023-04-19-cpg/index.html#helps-you-to-keep-a-tidy-folder",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Helps you to keep a tidy folder",
    "text": "Helps you to keep a tidy folder\nProject name\n├── LICENSE\n├── README.md          <- The top-level README for developers using this project.\n├── data\n│   ├── external       <- Data from third party sources.\n│   ├── interim        <- Intermediate data that has been transformed.\n│   ├── processed      <- The final, canonical data sets for modeling.\n│   └── raw            <- The original read only\n│\n├── docs               <- All the document information should go here\n│   ├── reports\n│   └── presentations\n│\n├── workflow           <- Source code and snakemake rules \n│   ├── Snakefile      <- A snakefile, should include all sub rules\n│   │\n│   ├── rules          <- Seperate snakefile rules\n│   │\n│   ├── environments   <- Conda environments\n│   │\n│   └── singularity    <- Singularity containers\n│ \n└── results\n\n\nA tidy folder keep your research trackable and reproducible."
  },
  {
    "objectID": "presentations/2023-04-19-cpg/index.html#available-on-github",
    "href": "presentations/2023-04-19-cpg/index.html#available-on-github",
    "title": "My Experience on Metagenomics and Workflows",
    "section": "Available on Github",
    "text": "Available on Github\n\nVersion controlling\nShare an collaborate\nAlso help you to backup\n\n\n\naMeta Workshop"
  }
]